{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = os.getcwd()\n",
    "p = os.path.dirname(d)\n",
    "\n",
    "sys.path.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dynamics import BurgersDynamics\n",
    "from src.algorithms.addpgpd_sampled import ADpgpdSampled\n",
    "from src.algorithms.pgdual import LinearDual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 10\n",
    "da = 10\n",
    "\n",
    "tau = 0.001\n",
    "gamma = 0.9\n",
    "alpha = 1.0\n",
    "\n",
    "viscosity = 0.1\n",
    "dt = 0.01\n",
    "dx = 1.0 / (ds - 1)\n",
    "\n",
    "b = -20\n",
    "\n",
    "G = - torch.diag(torch.tensor([1.0] * ds)).double()\n",
    "H = - torch.diag(torch.tensor([1.0] * da)).double() * (tau / 2)\n",
    "C = - torch.eye(da).double()\n",
    "\n",
    "def primal_reward_fn(env, a):\n",
    "    return ((env.u @ G) * env.u).sum(dim=1)\n",
    "\n",
    "def primal_reward_reg_fn(env, a):\n",
    "    return ((a @ H) * a).sum(dim=1)\n",
    "\n",
    "def dual_reward_fn(env, a):\n",
    "    return (a.abs() @ C).sum(dim=1)\n",
    "\n",
    "def starting_pos_fn(n_samples):\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    x = torch.linspace(0, 1, ds).double()\n",
    "    u = torch.sin(np.pi * x).repeat(n_samples, 1)\n",
    "    noise = torch.normal(0, 0.01, size=u.shape).double()\n",
    "    u += noise\n",
    "\n",
    "    a = torch.tensor(rng.uniform(\n",
    "        low=[-1] * da,\n",
    "        high=[1] * da,\n",
    "        size=[n_samples, da],\n",
    "    )).double()\n",
    "\n",
    "    return u, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - A-DPPG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A - Unconstrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2_000\n",
    "n_pe = 100\n",
    "n_rho = 100\n",
    "n_roll = 100\n",
    "\n",
    "eta = 0.01\n",
    "\n",
    "env = BurgersDynamics(ds, viscosity, dt, dx)\n",
    "dpgpd = ADpgpdSampled(ds, da, env, eta, tau, gamma, b, alpha, primal_reward_fn, primal_reward_reg_fn, dual_reward_fn, starting_pos_fn)\n",
    "\n",
    "K, losses_primal, losses_dual = dpgpd.train_unconstrained(epochs, n_pe, n_rho, n_roll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B - Constrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10_000\n",
    "n_pe = 100\n",
    "n_rho = 1_000\n",
    "n_roll = 100\n",
    "\n",
    "gamma = 0.9\n",
    "eta = 0.001\n",
    "\n",
    "env = BurgersDynamics(ds, viscosity, dt, dx)\n",
    "dpgpd = ADpgpdSampled(ds, da, env, eta, tau, gamma, b, alpha, primal_reward_fn, primal_reward_reg_fn, dual_reward_fn, starting_pos_fn)\n",
    "\n",
    "K, lmbda, losses_primal, losses_dual = dpgpd.train_constrained(epochs, n_pe, n_rho, n_roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../results/burg_primal.npy', losses_primal)\n",
    "np.save('../results/burg_dual.npy', losses_dual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - PGDual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10_000\n",
    "n_samples = 100\n",
    "n_rollout = 100\n",
    "n_rho = 1_000\n",
    "\n",
    "n_dual_update = 10\n",
    "lr_actor = 1e-3\n",
    "lr_dual = 1e-2\n",
    "\n",
    "env = BurgersDynamics(ds, viscosity, dt, dx)\n",
    "\n",
    "ld = LinearDual(ds, da, env, lr_actor, lr_dual, gamma, b, starting_pos_fn, primal_reward_fn, dual_reward_fn)\n",
    "loss_primal, loss_dual = ld.train(n_epochs, n_samples, n_rollout, n_rho, n_dual_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../results/burg_primal_dm.npy', loss_primal)\n",
    "np.save('../results/burg_dual_dm.npy', loss_dual)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
